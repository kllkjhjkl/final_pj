import os
import json
import argparse
from pathlib import Path
from typing import Dict, Any

def analyze_dataset(data_dir: Path) -> Dict[str, Any]:
    """åˆ†ææ•°æ®é›†ä¿¡æ¯"""
    info = {
        'has_transforms': False,
        'train_count': 0,
        'val_count': 0,
        'test_count': 0,
        'image_width': None,
        'image_height': None,
        'camera_angle_x': None,
        'has_white_background': True  # COLMAPæ•°æ®é€šå¸¸éœ€è¦ç™½è‰²èƒŒæ™¯
    }
    
    # æ£€æŸ¥transformsæ–‡ä»¶
    transforms_files = ['transforms_train.json', 'transforms_val.json', 'transforms_test.json']
    for tf in transforms_files:
        tf_path = data_dir / tf
        if tf_path.exists():
            info['has_transforms'] = True
            with open(tf_path, 'r') as f:
                data = json.load(f)
                
            if tf == 'transforms_train.json':
                info['train_count'] = len(data.get('frames', []))
                info['camera_angle_x'] = data.get('camera_angle_x')
            elif tf == 'transforms_val.json':
                info['val_count'] = len(data.get('frames', []))
            elif tf == 'transforms_test.json':
                info['test_count'] = len(data.get('frames', []))
    
    # æ£€æŸ¥å›¾åƒå°ºå¯¸ï¼ˆä»ç¬¬ä¸€å¼ è®­ç»ƒå›¾åƒï¼‰
    train_dir = data_dir / 'train'
    if train_dir.exists():
        image_files = list(train_dir.glob('*.png')) + list(train_dir.glob('*.jpg'))
        if image_files:
            try:
                import cv2
                img = cv2.imread(str(image_files[0]))
                if img is not None:
                    info['image_height'], info['image_width'] = img.shape[:2]
            except ImportError:
                print("è­¦å‘Š: æ— æ³•å¯¼å…¥cv2ï¼Œæ— æ³•æ£€æµ‹å›¾åƒå°ºå¯¸")
    
    return info

def generate_config(data_dir: Path, exp_name: str = None, 
                   output_file: Path = None, **kwargs) -> str:
    """ç”ŸæˆNeRFé…ç½®æ–‡ä»¶å†…å®¹"""
    
    # åˆ†ææ•°æ®é›†
    info = analyze_dataset(data_dir)
    
    if not info['has_transforms']:
        raise ValueError(f"åœ¨ {data_dir} ä¸­æœªæ‰¾åˆ°transformsæ–‡ä»¶ï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®è½¬æ¢COLMAPæ•°æ®")
    
    # è®¾ç½®é»˜è®¤å®éªŒå
    if exp_name is None:
        exp_name = f"colmap_{data_dir.name}"
    
    # åŸºç¡€é…ç½®
    config_lines = [
        f"expname = {exp_name}",
        f"basedir = ./logs",
        f"datadir = {data_dir.absolute()}",
        f"dataset_type = blender",
        "",
        "# æ•°æ®é›†ä¿¡æ¯",
        f"# è®­ç»ƒé›†: {info['train_count']} å¼ ",
        f"# éªŒè¯é›†: {info['val_count']} å¼ ", 
        f"# æµ‹è¯•é›†: {info['test_count']} å¼ ",
    ]
    
    if info['image_width'] and info['image_height']:
        config_lines.extend([
            f"# å›¾åƒå°ºå¯¸: {info['image_width']}x{info['image_height']}",
        ])
    
    config_lines.extend([
        "",
        "# åŸºç¡€è®¾ç½®",
        "no_batching = True",
        "use_viewdirs = True",
    ])
    
    # èƒŒæ™¯è®¾ç½®
    if info['has_white_background']:
        config_lines.append("white_bkgd = True")
    else:
        config_lines.append("white_bkgd = False")
    
    config_lines.extend([
        "",
        "# å­¦ä¹ ç‡è®¾ç½®",
        "lrate_decay = 500",
        "",
        "# é‡‡æ ·è®¾ç½®", 
        "N_samples = 64",
        "N_importance = 128",
        "N_rand = 1024",
    ])
    
    # æ ¹æ®å›¾åƒæ•°é‡è°ƒæ•´é‡‡æ ·è®¾ç½®
    total_images = info['train_count'] + info['val_count'] + info['test_count']
    if total_images < 100:
        # å›¾åƒè¾ƒå°‘æ—¶ï¼Œå¢åŠ é‡‡æ ·ç‚¹
        config_lines.extend([
            "",
            "# å›¾åƒè¾ƒå°‘ï¼Œå¢åŠ é‡‡æ ·å¯†åº¦",
            "N_samples = 128", 
            "N_importance = 256",
        ])
    elif total_images > 500:
        # å›¾åƒè¾ƒå¤šæ—¶ï¼Œå¯ä»¥é€‚å½“å‡å°‘é‡‡æ ·
        config_lines.extend([
            "",
            "# å›¾åƒè¾ƒå¤šï¼Œå¯é€‚å½“å‡å°‘é‡‡æ ·",
            "N_samples = 64",
            "N_importance = 128", 
        ])
    
    config_lines.extend([
        "",
        "# é¢„å¤„ç†è®¾ç½®",
        "precrop_iters = 500",
        "precrop_frac = 0.5",
    ])
    
    # æ ¹æ®å›¾åƒå°ºå¯¸å†³å®šæ˜¯å¦ä½¿ç”¨half_res
    if info['image_width'] and info['image_height']:
        if info['image_width'] * info['image_height'] > 1920 * 1080:
            config_lines.append("half_res = True  # å¤§å°ºå¯¸å›¾åƒï¼Œä½¿ç”¨åŠåˆ†è¾¨ç‡")
        else:
            config_lines.append("half_res = False  # ä¸­ç­‰å°ºå¯¸å›¾åƒï¼Œä½¿ç”¨å…¨åˆ†è¾¨ç‡")
    else:
        config_lines.append("half_res = True  # æœªçŸ¥å›¾åƒå°ºå¯¸ï¼Œå»ºè®®ä½¿ç”¨åŠåˆ†è¾¨ç‡")
    
    # æ·»åŠ ç”¨æˆ·è‡ªå®šä¹‰å‚æ•°
    if kwargs:
        config_lines.extend([
            "",
            "# è‡ªå®šä¹‰å‚æ•°"
        ])
        for key, value in kwargs.items():
            if isinstance(value, bool):
                config_lines.append(f"{key} = {str(value)}")
            elif isinstance(value, (int, float)):
                config_lines.append(f"{key} = {value}")
            else:
                config_lines.append(f"{key} = {value}")
    
    config_content = '\n'.join(config_lines)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    if output_file is None:
        output_file = data_dir / f"{exp_name}_config.txt"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(config_content)
    
    return config_content, output_file

def main():
    parser = argparse.ArgumentParser(description="ä¸ºCOLMAPè½¬æ¢çš„NeRFæ•°æ®ç”Ÿæˆé…ç½®æ–‡ä»¶")
    parser.add_argument("data_dir", help="åŒ…å«transformsæ–‡ä»¶çš„æ•°æ®ç›®å½•")
    parser.add_argument("--exp_name", help="å®éªŒåç§°ï¼Œé»˜è®¤ä½¿ç”¨ç›®å½•å")
    parser.add_argument("--output", help="è¾“å‡ºé…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--no_white_bkgd", action="store_true", help="ä¸ä½¿ç”¨ç™½è‰²èƒŒæ™¯")
    parser.add_argument("--full_res", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨å…¨åˆ†è¾¨ç‡")
    parser.add_argument("--half_res", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨åŠåˆ†è¾¨ç‡")
    parser.add_argument("--N_samples", type=int, help="ç²—é‡‡æ ·ç‚¹æ•°")
    parser.add_argument("--N_importance", type=int, help="ç»†é‡‡æ ·ç‚¹æ•°")
    parser.add_argument("--N_rand", type=int, help="æ¯æ‰¹éšæœºå…‰çº¿æ•°")
    
    args = parser.parse_args()
    
    data_dir = Path(args.data_dir)
    if not data_dir.exists():
        print(f"é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = ['transforms_train.json']
    missing_files = []
    for rf in required_files:
        if not (data_dir / rf).exists():
            missing_files.append(rf)
    
    if missing_files:
        print(f"é”™è¯¯: ç¼ºå°‘å¿…è¦æ–‡ä»¶: {missing_files}")
        print("è¯·ç¡®ä¿å·²ä½¿ç”¨COLMAPè½¬æ¢è„šæœ¬æ­£ç¡®ç”Ÿæˆäº†NeRFæ ¼å¼æ•°æ®")
        return
    
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶
    output_file = None
    if args.output:
        output_file = Path(args.output)
    
    # å‡†å¤‡è‡ªå®šä¹‰å‚æ•°
    custom_params = {}
    
    if args.no_white_bkgd:
        custom_params['white_bkgd'] = False
    
    if args.full_res:
        custom_params['half_res'] = False
    elif args.half_res:
        custom_params['half_res'] = True
        
    if args.N_samples:
        custom_params['N_samples'] = args.N_samples
    if args.N_importance:
        custom_params['N_importance'] = args.N_importance  
    if args.N_rand:
        custom_params['N_rand'] = args.N_rand
    
    try:
        config_content, output_path = generate_config(
            data_dir, 
            exp_name=args.exp_name,
            output_file=output_file,
            **custom_params
        )
        
        print("âœ… é…ç½®æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼")
        print(f"ğŸ“ ä¿å­˜ä½ç½®: {output_path}")
        print(f"\nğŸ“‹ é…ç½®æ–‡ä»¶å†…å®¹:")
        print("-" * 50)
        print(config_content)
        print("-" * 50)
        print(f"\nğŸš€ ä½¿ç”¨æ–¹æ³•:")
        print(f"python train.py --config {output_path}")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆé…ç½®æ–‡ä»¶å¤±è´¥: {e}")

if __name__ == "__main__":
    main()